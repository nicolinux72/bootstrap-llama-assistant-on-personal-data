# Bootstrap a LLaMa assistant on personalÂ data
How to quickly fine tuning a LLM so that it responds about private data also.

![Kindly created by stable diffusion XL](LLaMa.png)

In this second article, still aimed at beginners, we will enrich our AI chatbot with personal documents, such as PDFs on our laptop, so that it can respond even to topics for which it has not been pretrained, e.g. business know how. Confidentiality requirements, which we were inspired by, will remain so we will continue to use a local running LLM (Large Language Model), that is, without any calls to external APIs or licensing fees.
We will get familiar with LangChain, a well-maintained library that implements an abstraction on functionality common to all Natural Language Processing (NLP) applications such as, for example, using an LLM through different runtimes or enriching its knowledge base through spreadsheets, word processor documents or databases.
We will deepen our knowledge of generative AI models and introduce the concept of embeddings and vector databases. As usual, there will be no shortage of references to the annotated bibliography.

Please, read the full article on [medium.com](https://medium.com/@nicolasanti_43152/bootstrap-a-llama-assistant-on-personal-data-2-2-16062fa5aa6d)
